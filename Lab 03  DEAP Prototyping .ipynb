{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deap\n",
    "import cma\n",
    "from deap import cma\n",
    "\n",
    "from deap import creator , base , tools, algorithms\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction a DEAP : \n",
    "DEAP est une librairie qui permet de prototyper rapidement des algorithmes évolutionnaires et des algorithmes génétiques, elle contient des modes de perturbations, de sélection et de croisement plus ou moins sophistiqués qui sont mis a disposition sous forme d'outils.\n",
    "Dans cette partie nous allons essayer d'aller en compliquant les choses tout en présentant les différents outils implémentés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de types : \n",
    "Dans deap nous pouvons créer dynamiquement des types en utilisant le créateur. \\\n",
    "Généralement nous n'avons pas beaucoup de types a utiliser sauf pour la programmation génétique, on utilisera également \"base\" pour manipuler plusieurs classes de bases proposées par DEAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "La fonction create permet de créer un type, elle prend en paramètres un nom, une classe de base et des attributs\n",
    "chaque\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Les premiers type que l'on va créer serrons des fonctions de fitness, pour se faire nous utiliserons la classe \n",
    "Fitness présente dans base et comme attributs additionnels nous ajouterons l'attribut weight qui permet de : \n",
    "    - Préciser les poids des différents attributs pour les départager si besoin est\n",
    "    - Préciser le sens dans lequel on optimise i.e si on souhaite les maximiser ou les minimiser\n",
    "\"\"\"\n",
    "creator.create(\"Fitness_Function\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Multi_Objectif\", base.Fitness, weights=(-1.0, 1.0))\n",
    "# Pour utiliser un type crée on ecris par exemple creator.Fitness_Function\n",
    "\n",
    "\"\"\"\n",
    "A présent on va créer des individus, pour ce faire nous utiliserons généralement comme classe de base \n",
    "la classe liste que nous enrichirons par un attribut fitness qui aura un des types crées précédements.\n",
    "Dans la partie sur la programmation génétique on verra d'autres types plus exotiques.\n",
    "\"\"\"\n",
    "creator.create(\"Individual\", list, fitness=creator.Fitness_Function)\n",
    "#On aurait pu utiliser la classe ndarray dispo sur numpy comme classe de base\n",
    "creator.create(\"Individual2\", np.ndarray , fitness=creator.Fitness_Function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création et remplissage de la Toolbox : \n",
    "La toolbox est l'élément le plus important d'un algorithme génétique, elle permet de spécifier les différentes fonctions que l'on va utiliser pour perturber les solutions, pour les faire muter etc...\n",
    "Son remplissage nécessite d'utiliser la fonction register, et la encore pour la remplire nous pourrons nous appuyer sur les outils mis a disposition par deap.\\\n",
    "La toolbox sert également a préciser la structure de la population et comment l'initialiser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "D'abord on crée la population et on l'ajoute a la ToolBox \n",
    "\"\"\"\n",
    "#Taille de l'individu \n",
    "IND_SIZE = 10\n",
    "#Initialisation de la toolbox\n",
    "toolbox = base.Toolbox()\n",
    "#On enregistre la fonction qui sert a initialiser les individus \n",
    "toolbox.register(\"initialisation_random\", random.random)\n",
    "#On ajoute les individus en précisant le mode d'initialisation, le type la fonction d'initialisation et leur taille \n",
    "toolbox.register(\"population\", tools.initRepeat, creator.Individual,toolbox.initialisation_random, n=IND_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Maintenant je vais présenter chaque outils\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1/Fonction d'évaluation : \n",
    "\"\"\"\n",
    "#On crée un individu pour tester en utilisant \"individual\"\n",
    "\n",
    "individu1 = toolbox.population()\n",
    "print(individu1)\n",
    "print(individu1.fitness) #Fitness pas encore calculée\n",
    "print(individu1.fitness.valid) #Quand la fitness n'est pas calculée on dit qu'elle est invalide\n",
    "\n",
    "#D'abord comment enregistrer une fonction d'évaluation\n",
    "\n",
    "\n",
    "def evaluate(individual):\n",
    "    #Votre fonction d'évaluation qui retourne une ou plusieurs valeurs (autant qu'il n'y en a dans weights)\n",
    "    return 2,\n",
    "\n",
    "individu1.fitness.values = evaluate(individu1)\n",
    "#Aprés évaluation \n",
    "print (individu1.fitness.valid) #ça passe a valid parce qu'on a rempli le champ values\n",
    "print (individu1.fitness.values)\n",
    "\n",
    "#Maintenant on enregistre dans la toolbox comme ça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2/Opérateur de mutation (perturbation) : \n",
    "\"\"\"\n",
    "mutant = toolbox.clone(individu1)\n",
    "individu2, = tools.mutGaussian(mutant, mu=0.0, sigma=0.2, indpb=0.7)\n",
    "\n",
    "del mutant.fitness.values\n",
    "print(individu1)\n",
    "print(individu2)\n",
    "print(individu1.fitness.valid)\n",
    "print(individu2.fitness.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3/Opérateur de croisement (intensification) : \n",
    "\"\"\"\n",
    "child1, child2 = [toolbox.clone(ind) for ind in (individu1, individu2)]\n",
    "tools.cxBlend(child1, child2, 0.8)\n",
    "del child1.fitness.values\n",
    "del child2.fitness.values\n",
    "print(child1)\n",
    "print(child2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4/Opérateur de selection (intensification) : \n",
    "\"\"\"\n",
    "Lambd = 3\n",
    "MU = 10\n",
    "selected = tools.selBest([child1, child2], 1)\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on assemble le tout dans une seule bulle ce qui nous fait notre premier algorithme évolutionnaire, nous considérons le design suivant : \n",
    "- Une stratégie de perturbation qui consiste a inverser un bit.\n",
    "- Une sélection par tournoi\n",
    "- Un croisement Binaire qui consiste en l'inversion de deux points.\n",
    "\n",
    "Le probléme que nous allons résoudre pour voire si ça marche est le problème de maximum binaire, la fonction d'évaluation serra donc naturellement la somme des éléments de la liste et on s'attend a la fin a trouver un vecteur de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator \n",
    "#                      define 'attr_bool' to be an attribute ('gene')\n",
    "#                      which corresponds to integers sampled uniformly\n",
    "#                      from the range [0,1] (i.e. 0 or 1 with equal\n",
    "#                      probability)\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "\n",
    "# Structure initializers\n",
    "#                         define 'individual' to be an individual\n",
    "#                         consisting of 100 'attr_bool' elements ('genes')\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "                 toolbox.attr_bool, 100)\n",
    "\n",
    "# define the population to be a list of individuals\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "# the goal ('fitness') function to be maximized\n",
    "def evaluation_func(individual):\n",
    "    return sum(individual),\n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluation_func)\n",
    "\n",
    "\n",
    "# ----------\n",
    "# Ajout des opérateurs \n",
    "# ----------\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "# ----------\n",
    "\n",
    "random.seed(64)\n",
    "# create an initial population of 300 individuals (where\n",
    "# each individual is a list of integers)\n",
    "pop = toolbox.population(n=300)\n",
    "\"\"\"\n",
    "Supposons qu'on adopte un mécanisme connu consistant a assigner des probabilités : \n",
    "    -CXPB : Probabilités de croisements.\n",
    "    -MUTPB : Probabilités de mutations.\n",
    "Ne pas oublier que les mutation diversifient la recherche donc souvent il ne faut pas en abuser pour une bonne\n",
    "convergence\n",
    "\"\"\"\n",
    "CXPB, MUTPB = 0.5, 0.2\n",
    "\n",
    "print(\"Start of evolution\")\n",
    "# Evaluer la population\n",
    "fitnesses = list(map(toolbox.evaluate, pop))\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "    \n",
    "\n",
    "print(\"  Evaluated %i individuals\" % len(pop))\n",
    "# Met les fitnesses dans une liste\n",
    "fits = [ind.fitness.values[0] for ind in pop]\n",
    "gen = 0\n",
    "# Begin the evolution\n",
    "while max(fits) < 100 and g < 1000:\n",
    "    # A new generation\n",
    "    gen = gen + 1\n",
    "    print(\"---- Iteration : %i ----\" % gen)\n",
    "    \n",
    "    # On sélectionne des individus (supposons que tous les éléments parents participent a la génération de l'offspring)\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    \n",
    "    # On les clone etant donné que les oppérateurs aggissent in place et on récupére une liste de références\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "    \n",
    "    # on croise les éléments paires avec les éléments impaires suivant une probabilité CXPB\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1, child2)\n",
    "            #On déléte les fitness, vu que les éléments ont changés elle doit être recalculée\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "            \n",
    "    \n",
    "    for mutant in offspring:\n",
    "        #Mutation avec probabilité MUTPB\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    print(\"  Evaluated %i individuals\" % len(invalid_ind))\n",
    "    # The population is entirely replaced by the offspring\n",
    "    pop[:] = offspring\n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x * x for x in fits)\n",
    "    std = abs(sum2 / length - mean ** 2) ** 0.5\n",
    "    print(\"  Min %s\" % min(fits))\n",
    "    print(\"  Max %s\" % max(fits))\n",
    "    print(\"  Avg %s\" % mean)\n",
    "    print(\"  Std %s\" % std)\n",
    "print(\"-- End of (successful) evolution --\")\n",
    "best_ind = tools.selBest(pop, 1)[0]\n",
    "print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Un peu trop long ? \n",
    "Il existe un autre moyen de coder ces comportements basiques (tellement basiques que même moi j'ai copié des\n",
    "partie de ce code du code de mon prof qui l'a copié du code de la librairie) et c'est en utilisant le package\n",
    "algorithms.\n",
    "\"\"\"\n",
    "pop = toolbox.population(n=300)\n",
    "log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.1, ngen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Un peu triste comme display...\n",
    "On peut le customiser en demandant a l'algorithme de calculer des statistiques grace au package stats.\n",
    "\"\"\"\n",
    "pop = toolbox.population(n=300)\n",
    "#Initialiser l'objet stats en lui précisant une fonction lui permettant de savoir pour chaque individu sur quoi\n",
    "#il est sensé calculer ces stats.\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "#On ajoute des statistiques que l'on veut avoir \n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "#Pour l'executer sur une population on pourrait faire compile\n",
    "#Mais la le but est de le donner a l'algorithme\n",
    "log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.3, ngen=100,stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "On retrouve également les autres algorithmes évolutionnaires connus.\n",
    "\"\"\"\n",
    "pop = toolbox.population(n=300)\n",
    "#Décomenter pour tester si vous voulez tester\n",
    "#l= algorithms.eaMuPlusLambda(pop, toolbox, mu=300, lambda_=100, cxpb=0.5, mutpb=0.3, ngen=200, stats=stats)\n",
    "#l= algorithms.eaMuCommaLambda(pop, toolbox, mu=300, lambda_=400, cxpb=0.5, mutpb=0.3, ngen=200, stats=stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également manipuler des stratégies, par exemple CMA-ES qu'on a vu précédemment a été développé en utilisant deap et par conséquent on peut utiliser cette stratégie :\n",
    "- generate permet de générer une population a partir d'un élément.\n",
    "- update permet d'actualiser a partir d'une population évaluée les paramètres permettant de generer des éléments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "                 toolbox.attr_bool, 100)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "def evaluation_func(individual):\n",
    "    return sum(individual),\n",
    "toolbox.register(\"evaluate\", evaluation_func)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "pop = toolbox.population(n=300)\n",
    "\n",
    "S = cma.Strategy(centroid = pop[0],sigma = 0.01)\n",
    "toolbox.register(\"generate\", S.generate, creator.Individual)\n",
    "toolbox.register(\"update\",S.update)\n",
    "\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "#On ajoute des statistiques que l'on veut avoir \n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "\n",
    "\n",
    "\n",
    "for g in range(100):\n",
    "    pop = toolbox.generate()\n",
    "    evaluate(pop)\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    toolbox.update(pop)\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=g, **record)\n",
    "    logbook.header = \"gen\", \"avg\", \"max\"\n",
    "    print(logbook.stream)\n",
    "\n",
    "\"\"\"\n",
    "Quelqu'un peut expliquer pourquoi ça marche pas ??\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Nous de jouer : \n",
    "On va essayer cette fois ci de prototyper rapidement un algorithme génétique de notre choix sur le dataset boston en utilisant les mêmes fonctions d'évaluations que précédément et le même réseau de neurones.\n",
    "Vous choisissez l'algorithme que vous voulez et on voit qui a le meilleur résultat en 1000 itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La fonction d'évaluation : \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "def evaluation_function(w):\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "    Network = SimpleNeuralControllerNumpy(13, 1, n_hidden_layers=0, n_neurons_per_hidden=0, params=None)\n",
    "    Network.set_parameters(w)\n",
    "    y_pred = Network.predict(X)\n",
    "    return mean_squared_error(y,y_pred),\n",
    "\n",
    "#Je vous remet la classe NeuralNetwork pour rappel (et pour éviter de l'importer)\n",
    "def sigmoid(x):\n",
    "    return 1./(1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "class SimpleNeuralControllerNumpy():\n",
    "    def __init__(self, n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5, params=None):\n",
    "        self.dim_in = n_in\n",
    "        self.dim_out = n_out\n",
    "        # if params is provided, we look for the number of hidden layers and neuron per layer into that parameter (a dicttionary)\n",
    "        if (not params==None):\n",
    "            if (\"n_hidden_layers\" in params.keys()):\n",
    "                n_hidden_layers=params[\"n_hidden_layers\"]\n",
    "            if (\"n_neurons_per_hidden\" in params.keys()):\n",
    "                n_neurons_per_hidden=params[\"n_neurons_per_hidden\"]\n",
    "        self.n_per_hidden = n_neurons_per_hidden\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.weights = None \n",
    "        self.n_weights = None\n",
    "        self.init_random_params()\n",
    "        self.out = np.zeros(n_out)\n",
    "        #print(\"Creating a simple mlp with %d inputs, %d outputs, %d hidden layers and %d neurons per layer\"%(n_in, n_out,n_hidden_layers, n_neurons_per_hidden))\n",
    "    def init_random_params(self):\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            self.weights = [np.random.random((self.dim_in,self.n_per_hidden))] # In -> first hidden\n",
    "            self.bias = [np.random.random(self.n_per_hidden)] # In -> first hidden\n",
    "            for i in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                self.weights.append(np.random.random((self.n_per_hidden,self.n_per_hidden)))\n",
    "                self.bias.append(np.random.random(self.n_per_hidden))\n",
    "            self.weights.append(np.random.random((self.n_per_hidden,self.dim_out))) # -> last hidden -> out\n",
    "            self.bias.append(np.random.random(self.dim_out))\n",
    "        else:\n",
    "            self.weights = [np.random.random((self.dim_in,self.dim_out))] # Single-layer perceptron\n",
    "            self.bias = [np.random.random(self.dim_out)]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all network parameters as a single array\n",
    "        \"\"\"\n",
    "        flat_weights = np.hstack([arr.flatten() for arr in (self.weights+self.bias)])\n",
    "        return flat_weights\n",
    "\n",
    "    def set_parameters(self, flat_parameters):\n",
    "        \"\"\"\n",
    "        Set all network parameters from a single array\n",
    "        \"\"\"\n",
    "        i = 0 # index\n",
    "        to_set = []\n",
    "        self.weights = list()\n",
    "        self.bias = list()\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            # In -> first hidden\n",
    "            w0 = np.array(flat_parameters[i:(i+self.dim_in*self.n_per_hidden)])\n",
    "            self.weights.append(w0.reshape(self.dim_in,self.n_per_hidden))\n",
    "            i += self.dim_in*self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                w = np.array(flat_parameters[i:(i+self.n_per_hidden*self.n_per_hidden)])\n",
    "                self.weights.append(w.reshape((self.n_per_hidden,self.n_per_hidden)))\n",
    "                i += self.n_per_hidden*self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            wN = np.array(flat_parameters[i:(i+self.n_per_hidden*self.dim_out)])\n",
    "            self.weights.append(wN.reshape((self.n_per_hidden,self.dim_out)))\n",
    "            i += self.n_per_hidden*self.dim_out\n",
    "            # Samefor bias now\n",
    "            # In -> first hidden\n",
    "            b0 = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "            self.bias.append(b0)\n",
    "            i += self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                b = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "                self.bias.append(b)\n",
    "                i += self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            bN = np.array(flat_parameters[i:(i+self.dim_out)])\n",
    "            self.bias.append(bN)\n",
    "            i += self.dim_out\n",
    "        else:\n",
    "            n_w = self.dim_in*self.dim_out\n",
    "            w = np.array(flat_parameters[:n_w])\n",
    "            self.weights = [w.reshape((self.dim_in,self.dim_out))]\n",
    "            self.bias = [np.array(flat_parameters[n_w:])]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "    \n",
    "    def predict(self,x):\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            #Input\n",
    "            a = np.matmul(x,self.weights[0]) + self.bias[0]\n",
    "            #y = sigmoid(a)\n",
    "            y = a\n",
    "            # hidden -> hidden\n",
    "            for i in range(1,self.n_hidden_layers-1):\n",
    "                a = np.matmul(y, self.weights[i]) + self.bias[i]\n",
    "                y = sigmoid(a)\n",
    "            # Out\n",
    "            a = np.matmul(y, self.weights[-1]) + self.bias[-1]\n",
    "            #out = tanh(a)\n",
    "            out = a\n",
    "            return out\n",
    "        else: # Simple monolayer perceptron\n",
    "            #return tanh(np.matmul(x,self.weights[0]) + self.bias[0])\n",
    "            return np.matmul(x,self.weights[0]) + self.bias[0]\n",
    "        \n",
    "#Et voila pour rappel comment on initialise les paramètres aléatoirement\n",
    "Network = SimpleNeuralControllerNumpy(13, 1, n_hidden_layers=0, n_neurons_per_hidden=0, params=None)\n",
    "Network.init_random_params()\n",
    "print(Network.get_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "\n",
    "toolbox.register(\"attr_bool\", random.random)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "                 toolbox.attr_bool, len(Network.get_parameters()))\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluation_function)\n",
    "toolbox.register(\"mate\", tools.cxSimulatedBinary,eta=15)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian,mu = 0, sigma=0.01, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "pop = toolbox.population(n=300)\n",
    "\n",
    "l= algorithms.eaMuPlusLambda(pop, toolbox, mu=300, lambda_=100, cxpb=0.5, mutpb=0.3, ngen=200, stats=stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cma.Strategy(centroid = pop[0],sigma = 0.01)\n",
    "toolbox.register(\"generate\", S.generate, creator.Individual)\n",
    "toolbox.register(\"update\",S.update)\n",
    "\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "#On ajoute des statistiques que l'on veut avoir \n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "\n",
    "\n",
    "\n",
    "for g in range(1000):\n",
    "    pop = toolbox.generate()\n",
    "    evaluate(pop)\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    toolbox.update(pop)\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=g, **record)\n",
    "    logbook.header = \"gen\", \"avg\", \"min\"\n",
    "    print(logbook.stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
